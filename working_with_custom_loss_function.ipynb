{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a custom loss function\n",
    "\n",
    "This project was a part of **Machine Learning Specialization with TF2** by [**CLOUDXLAB**](http://cloudxlab.com/).\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split( housing.data,\n",
    "         housing.target.reshape(-1, 1), random_state=42)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid =  train_test_split( X_train_full, \n",
    "        y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_scaled = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a Custom Loss Function - Huber Loss\n",
    "Let's implement huber loss. Huber loss is less sensitive to outliers in data than mean squared error.\n",
    "\n",
    "Below is the formula of huber loss.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "**Note:**\n",
    "\n",
    "- Huber loss is defined as:\n",
    "\n",
    "    - error **2 / 2, if error < delta (ie, if it is a small error)\n",
    "\n",
    "    - delta * ( |error| - delta/2), otherwise ( |error| means the absolute value error)\n",
    "\n",
    "In this exercise, we consider delta=1.\n",
    "\n",
    "Thus, the **huber_fn** is defined as:\n",
    "    \n",
    "    - error**2/2, if error < 1 (ie, if it is a small error).\n",
    "    - |error| - 0.5, otherwise\n",
    "\n",
    "- tf.abs(x) returns the positive value(absolute value) of x.\n",
    "\n",
    "- tf.square(x) returns the squared value of x.\n",
    "\n",
    "- tf.where(bool_array, x, y) returns the elements where condition is True in bool_array (multiplexing x and y).\n",
    "\n",
    "In simpler terms, tf.where will choose an output shape from the shapes of condition, x, and y that all three shapes are broadcastable to.\n",
    "\n",
    "The condition tensor acts as a mask that chooses whether the corresponding element/row in the output should be taken from x (if the element in the condition is True) or from y (if it is False).\n",
    "\n",
    "For example, upon executing the following,\n",
    "\n",
    "tf.where([True, False, False, True], [1,2,3,4], [100,200,300,400])\n",
    "\n",
    "the output would be : <tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 1, 200, 300, 4], dtype=int32)>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < 1\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = tf.abs(error) - 0.5\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", \n",
    "       kernel_initializer=\"lecun_normal\", \n",
    "       input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=huber_fn, optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/15\n",
      "11610/11610 [==============================] - 1s 119us/sample - loss: 0.5935 - mae: 0.9491 - val_loss: 0.2426 - val_mae: 0.5450\n",
      "Epoch 2/15\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.2168 - mae: 0.5173 - val_loss: 0.2072 - val_mae: 0.4940\n",
      "Epoch 3/15\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.2066 - mae: 0.5006 - val_loss: 0.1906 - val_mae: 0.4761\n",
      "Epoch 4/15\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.2013 - mae: 0.4925 - val_loss: 0.1891 - val_mae: 0.4690\n",
      "Epoch 5/15\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.1972 - mae: 0.4858 - val_loss: 0.1792 - val_mae: 0.4599\n",
      "Epoch 6/15\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.1935 - mae: 0.4801 - val_loss: 0.1769 - val_mae: 0.4548\n",
      "Epoch 7/15\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.1912 - mae: 0.4757 - val_loss: 0.1781 - val_mae: 0.4534\n",
      "Epoch 8/15\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.1882 - mae: 0.4715 - val_loss: 0.1832 - val_mae: 0.4579\n",
      "Epoch 9/15\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.1856 - mae: 0.4674 - val_loss: 0.1771 - val_mae: 0.4526\n",
      "Epoch 10/15\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.1838 - mae: 0.4636 - val_loss: 0.1900 - val_mae: 0.4617\n",
      "Epoch 11/15\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.1826 - mae: 0.4619 - val_loss: 0.1850 - val_mae: 0.4595\n",
      "Epoch 12/15\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.1813 - mae: 0.4591 - val_loss: 0.1848 - val_mae: 0.4596\n",
      "Epoch 13/15\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.1796 - mae: 0.4574 - val_loss: 0.1915 - val_mae: 0.4655\n",
      "Epoch 14/15\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.1781 - mae: 0.4541 - val_loss: 0.1934 - val_mae: 0.4639\n",
      "Epoch 15/15\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.1767 - mae: 0.4505 - val_loss: 0.1805 - val_mae: 0.4494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f02c0714278>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled,y_train, epochs=15,\n",
    "  validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 29us/sample - loss: 0.1744 - mae: 0.4508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1743710722110068, 0.45079333]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the values of loss and mae. These values are nearly the same as those of the train and validation datasets. Also, the values are low. Hence our model hasn't been overfitted and is giving a decent performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
